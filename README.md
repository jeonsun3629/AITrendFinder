# Trend Finder ğŸ”¦

**Stay on top of trending topics on social media â€” all in one place.**

Trend Finder collects and analyzes posts from key influencers, then sends a Slack or Discord notification when it detects new trends or product launches. This has been enhanced with open-source crawl4ai technology to provide intelligent web crawling with LLM capabilities.

- **Saving time** normally spent manually searching social channels
- **Keeping you informed** of relevant, real-time conversations
- **Enabling rapid response** to new opportunities or emerging industry shifts

_Spend less time hunting for trends and more time creating impactful campaigns._

## Watch the Demo & Tutorial video

[![Thumbnail](https://i.ytimg.com/vi/puimQSun92g/hqdefault.jpg)](https://www.youtube.com/watch?v=puimQSun92g)

Learn how to set up Trend Finder and start monitoring trends in this video!

## How it Works

1. **Data Collection** ğŸ“¥
   - Monitors selected influencers' posts on Twitter/X using the X API (Warning: the X API free plan is rate limited to only monitor 1 X account every 15 min)
   - Monitors websites for new releases and news with crawl4ai's intelligent LLM-powered crawling
   - Runs on a scheduled basis using cron jobs and GitHub Actions

2. **AI Analysis** ğŸ§ 
   - Processes collected content through Together AI, DeepSeek, or OpenAI
   - Identifies emerging trends, releases, and news
   - Analyzes sentiment and relevance

3. **Notification System** ğŸ“¢
   - When significant trends are detected, sends Slack or Discord notifications based on cron job setup
   - Provides context about the trend and its sources
   - Enables quick response to emerging opportunities

## Features

- ğŸ¤– AI-powered trend analysis using Together AI, DeepSeek, or OpenAI
- ğŸ“± Social media monitoring (Twitter/X integration)
- ğŸ” Website monitoring with crawl4ai (open-source LLM-friendly crawler)
- ğŸ’¬ Instant Slack or Discord notifications
- â±ï¸ Scheduled monitoring using GitHub Actions

## Prerequisites

- Node.js (v14 or higher)
- Python 3.10 or higher
- npm or yarn
- Slack workspace with webhook permissions
- API keys for required services

## Environment Variables

Copy `.env.example` to `.env` and configure the following variables:

```
# Required: At least one API key for LLM services
# Used for both trend analysis and crawl4ai's LLM-powered browsing

# Option 1: API key from Together AI (https://www.together.ai/)
TOGETHER_API_KEY=your_together_api_key

# Option 2: API key from DeepSeek (https://deepseek.com/)
DEEPSEEK_API_KEY=your_deepseek_api_key

# Option 3: API key from OpenAI (https://openai.com/)
OPENAI_API_KEY=your_openai_api_key

# Required if monitoring Twitter/X trends (https://developer.x.com/)
X_API_BEARER_TOKEN=your_twitter_api_bearer_token_here

# Notification driver. Supported drivers: "slack", "discord", "notion"
NOTIFICATION_DRIVER=discord

# Required (if NOTIFICATION_DRIVER is "slack"): Incoming Webhook URL from Slack for notifications
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/YOUR/WEBHOOK/URL

# Required (if NOTIFICATION_DRIVER is "discord"): Incoming Webhook URL from Discord for notifications
DISCORD_WEBHOOK_URL=https://discord.com/api/webhooks/WEBHOOK/URL

# Optional: Notion API integration
NOTION_API_KEY=your_notion_api_key
NOTION_DATABASE_ID=your_notion_database_id

# Optional: Supabase URL and key for content storage
SUPABASE_URL=your_supabase_url
SUPABASE_ANON_KEY=your_supabase_anon_key
```

## Getting Started

1. **Clone the repository:**
   ```bash
   git clone [repository-url]
   cd trend-finder
   ```

2. **Install dependencies:**
   ```bash
   npm install
   pip install git+https://github.com/unclecode/crawl4ai.git
   ```

3. **Configure environment variables:**
   ```bash
   cp .env.example .env
   # Edit .env with your configuration
   ```

4. **Run the application:**
   ```bash
   # Development mode with hot reloading
   npm run start

   # Build for production
   npm run build
   ```

## Using GitHub Actions

This project is configured to run automatically using GitHub Actions. The workflow:

1. Sets up both Node.js and Python environments
2. Installs crawl4ai directly from GitHub
3. Runs the trend analysis on a schedule
4. Handles notifications based on your configuration

You can also manually trigger the workflow through the GitHub Actions tab.

## Project Structure

```
trend-finder/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ controllers/    # Request handlers
â”‚   â”œâ”€â”€ services/       # Business logic
â”‚   â”œâ”€â”€ scripts/        # Python scripts for crawl4ai
â”‚   â””â”€â”€ index.ts        # Application entry point
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/      # GitHub Actions definitions
â”œâ”€â”€ .env.example        # Environment variables template
â”œâ”€â”€ package.json        # Dependencies and scripts
â””â”€â”€ tsconfig.json       # TypeScript configuration
```

## Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ì „ì²´ ì›ë¬¸ ì €ì¥ ê¸°ëŠ¥

AITrendFinderëŠ” í¬ë¡¤ë§í•œ ì „ì²´ ì›ë¬¸ì„ Supabaseì— ì €ì¥í•˜ëŠ” ê¸°ëŠ¥ì„ ì§€ì›í•©ë‹ˆë‹¤. ì´ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë©´ Notion APIì˜ 2000ì ì œí•œì„ ìš°íšŒí•˜ì—¬ ì›ë¬¸ ì „ì²´ë¥¼ ë³´ì¡´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ì„¤ì • ë°©ë²•

1. [Supabase](https://supabase.com)ì— ê°€ì…í•˜ê³  ìƒˆ í”„ë¡œì íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
2. SQL ì—ë””í„°ì—ì„œ ë‹¤ìŒ ì¿¼ë¦¬ë¥¼ ì‹¤í–‰í•˜ì—¬ í•„ìš”í•œ í…Œì´ë¸”ê³¼ ì €ì¥ì†Œë¥¼ ìƒì„±í•©ë‹ˆë‹¤:

```sql
-- ì½˜í…ì¸  ì €ì¥ì„ ìœ„í•œ í…Œì´ë¸” ìƒì„±
CREATE TABLE article_contents (
  id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
  story_id TEXT NOT NULL UNIQUE,
  headline TEXT,
  content_full TEXT,
  storage_path TEXT,
  content_length INTEGER,
  created_at TIMESTAMPTZ DEFAULT NOW()
);

-- ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_article_contents_story_id ON article_contents(story_id);

-- ì €ì¥ì†Œ ë²„í‚· ìƒì„±
INSERT INTO storage.buckets (id, name, public) 
VALUES ('article-contents', 'article-contents', false);
```

3. `.env` íŒŒì¼ì— Supabase ê´€ë ¨ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤:

```
SUPABASE_URL=your_supabase_project_url
SUPABASE_ANON_KEY=your_supabase_anon_key
```

### ì‘ë™ ë°©ì‹

1. í¬ë¡¤ë§ ë‹¨ê³„ì—ì„œ ê° ê¸°ì‚¬ì˜ ì „ì²´ ì›ë¬¸ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
2. ì›ë¬¸ ê¸¸ì´ì— ë”°ë¼ ìë™ìœ¼ë¡œ ì €ì¥ ë°©ì‹ì´ ê²°ì •ë©ë‹ˆë‹¤:
   - ì§§ì€ ì›ë¬¸ (100KB ë¯¸ë§Œ): Supabase ë°ì´í„°ë² ì´ìŠ¤ì— ì§ì ‘ ì €ì¥
   - ê¸´ ì›ë¬¸ (100KB ì´ìƒ): Supabase Storageì— íŒŒì¼ë¡œ ì €ì¥
3. Notionì— ì €ì¥ ì‹œ, ì „ì²´ ì›ë¬¸ì´ ìˆëŠ” ê²½ìš° ìë™ìœ¼ë¡œ ê°€ì ¸ì™€ Content_full í•„ë“œì— ì €ì¥í•©ë‹ˆë‹¤.

## crawl4ai í†µí•©

ì´ í”„ë¡œì íŠ¸ëŠ” [crawl4ai](https://github.com/unclecode/crawl4ai)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹ì‚¬ì´íŠ¸ í¬ë¡¤ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. crawl4aiëŠ” ì˜¤í”ˆì†ŒìŠ¤ LLM ê¸°ë°˜ ì›¹ í¬ë¡¤ëŸ¬ë¡œ, ë‹¤ìŒê³¼ ê°™ì€ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:

- LLM ê¸°ë°˜ ìë™ ë„¤ë¹„ê²Œì´ì…˜ìœ¼ë¡œ ë³µì¡í•œ ì›¹ì‚¬ì´íŠ¸ êµ¬ì¡° íƒìƒ‰
- ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜ëœ ê¹”ë”í•œ ì½˜í…ì¸  ì¶”ì¶œ
- ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ë‚ ì§œ, ì´ë¯¸ì§€ URL ë“±)
- ë‹¤ì–‘í•œ LLM í”„ë¡œë°”ì´ë” ì§€ì› (OpenAI, Together AI, DeepSeek ë“±)

crawl4aiëŠ” GitHub Actions í™˜ê²½ì—ì„œ ìë™ìœ¼ë¡œ ì„¤ì¹˜ë˜ê³  ì‹¤í–‰ë©ë‹ˆë‹¤. ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œëŠ” ì•„ë˜ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```bash
pip install git+https://github.com/unclecode/crawl4ai.git
```
